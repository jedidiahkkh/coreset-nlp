{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2731d4e8-e479-47b6-8e20-ad5e28c615fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf48e7cd-499b-4d97-96c8-d41a448aede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 142919.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████| 10000/10000 [00:00<00:00, 188978.58 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████| 550152/550152 [00:01<00:00, 495085.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset('snli')\n",
    "ds.save_to_disk('data/snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfbd03-ad50-438c-9fbb-89e8aac46fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "token = AutoTokenizer.from_pretrained(model_name)\n",
    "token.save_pretrained('data/token')\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.save_pretrained('data/bert_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b720da2-bde9-49f1-871e-f436ea2052e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.save_pretrained('data/bert_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "369ddd85-e456-4e48-ac6c-d4876a4d6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('data/token')\n",
    "headless = AutoModel.from_pretrained('data/bert_normal')\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained('data/bert_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd473d5c-ac67-409c-b8b6-eaae805dc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk('data/snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83f5974-50d0-4cbd-b6fa-4fcd34eab67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "        return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4f37c66-9d51-44c0-ba01-6da0988f923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87b28a2a-8417-4605-ab72-54e3d65f2553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 550152\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96ad0786-7865-4a68-9450-9f4d81628064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5314f58f-fda5-459d-81ba-40f095feef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(np.arange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61ab093b-a35d-45db-a542-c08939c9455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 10902.57 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████| 998/998 [00:00<00:00, 3377.54 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 998/998 [00:00<00:00, 23568.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda batch: np.array(batch[\"label\"]) != -1, batched=True)\n",
    "dataset = dataset.map(encode, batched=True)\n",
    "dataset = dataset.map(lambda examples: {\"labels\": examples[\"label\"]}, batched=True)\n",
    "dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6617f641-4d34-44cd-9921-29e17c7fca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "          2091, 13297,  1012,   102,  1037,  2711,  2003,  2731,  2010,  3586,\n",
       "          2005,  1037,  2971,  1012,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e310bf9-edd8-4dab-9ce1-f53c179b1556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "          2091, 13297,  1012,   102,  1037,  2711,  2003,  2731,  2010,  3586,\n",
       "          2005,  1037,  2971,  1012,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.remove_columns('labels')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78d3029f-e992-4480-a8fd-de416bf05f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headless.eval()\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8175bb5-17bc-4430-8570-8922ec0a7b9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.8701,  0.1044, -0.8448,  ..., -0.7244,  0.2107,  0.1728],\n",
      "         [-0.8112,  0.1907, -0.9818,  ..., -0.3051,  0.4335,  0.0024],\n",
      "         [-1.1000, -0.3378, -0.5038,  ..., -0.3010,  0.1676, -0.4993],\n",
      "         ...,\n",
      "         [ 0.2257, -0.6626,  0.3625,  ..., -0.3866, -0.8420, -0.8623],\n",
      "         [ 0.6308,  0.0563, -0.5607,  ..., -0.0981, -0.4543, -0.2846],\n",
      "         [ 0.6324,  0.0537, -0.5595,  ..., -0.0900, -0.4814, -0.2747]]]), pooler_output=tensor([[-0.9884, -0.9076, -0.9998,  0.9898,  0.9931, -0.8266,  0.9948,  0.8217,\n",
      "         -0.9989, -1.0000, -0.9813,  0.9996,  0.9930,  0.9704,  0.9863, -0.9851,\n",
      "         -0.9729, -0.9264,  0.8106, -0.9316,  0.9574,  1.0000, -0.8754,  0.8351,\n",
      "          0.9131,  1.0000, -0.9784,  0.9803,  0.9808,  0.8880, -0.9737,  0.7851,\n",
      "         -0.9968, -0.7635, -0.9998, -0.9993,  0.9240, -0.9121, -0.7272, -0.6074,\n",
      "         -0.9706,  0.8622,  1.0000,  0.6741,  0.9449, -0.8274, -1.0000,  0.8292,\n",
      "         -0.9634,  0.9999,  0.9995,  0.9995,  0.8275,  0.9237,  0.9271, -0.9553,\n",
      "          0.6997,  0.7782, -0.8134, -0.9382, -0.9012,  0.8590, -0.9987, -0.9677,\n",
      "          0.9999,  0.9989, -0.8807, -0.8218, -0.8440,  0.6756,  0.9928,  0.8368,\n",
      "         -0.7812, -0.9240,  0.9974,  0.8881, -0.8861,  1.0000, -0.9722, -0.9940,\n",
      "          0.9982,  0.9983,  0.8799, -0.9913,  0.9808, -1.0000,  0.9653, -0.7060,\n",
      "         -0.9957,  0.7840,  0.9667, -0.8371,  0.9921,  0.9129, -0.9627, -0.9525,\n",
      "         -0.9174, -0.9988, -0.8671, -0.9400,  0.7418, -0.8424, -0.9534, -0.8433,\n",
      "          0.8994, -0.9350, -0.9225,  0.8891,  0.9198,  0.9487,  0.8285, -0.8347,\n",
      "          0.9433, -0.9861,  0.9588, -0.8397, -0.9960, -0.8782, -0.9950,  0.9238,\n",
      "         -0.9200, -0.8744,  0.9897, -0.9542,  0.8707, -0.8314, -0.9998, -1.0000,\n",
      "         -0.9655, -0.9546, -0.8659, -0.8993, -0.9902, -0.9790,  0.9610,  0.9822,\n",
      "          0.8117,  1.0000, -0.8929,  0.9784, -0.9536, -0.9877,  0.9930, -0.9265,\n",
      "          0.9862,  0.9176, -0.9673,  0.8304, -0.9204,  0.9416, -0.9912, -0.8867,\n",
      "         -0.9979, -0.9545, -0.8049,  0.9805, -0.9878, -0.9999, -0.9186, -0.8132,\n",
      "         -0.9311,  0.9576,  0.9807,  0.8835, -0.9103,  0.9061,  0.9535,  0.9292,\n",
      "         -0.9706, -0.8799,  0.9021, -0.8518, -0.9992, -0.9938, -0.9233,  0.8237,\n",
      "          0.9962,  0.9337,  0.8457,  0.9974, -0.8225,  0.9799, -0.9876,  0.9957,\n",
      "         -0.7927,  0.7119, -0.9622,  0.9326, -0.9776,  0.8259,  0.9918, -0.9796,\n",
      "         -0.9083, -0.8477, -0.8424, -0.9026, -0.9957,  0.8896, -0.8351, -0.7914,\n",
      "         -0.7891,  0.9668,  0.9997,  0.9258,  0.9861,  0.9408, -0.9802, -0.8912,\n",
      "          0.8210,  0.8001,  0.8260,  0.9982, -0.9693, -0.8331, -0.9664, -0.9931,\n",
      "          0.7234, -0.9718, -0.8060, -0.9353,  0.9842, -0.9713,  0.9846,  0.8679,\n",
      "         -0.9997, -0.9629,  0.8892, -0.8971,  0.9312, -0.8051,  0.9310,  0.9997,\n",
      "         -0.9427,  0.9872,  0.9783, -0.9993, -0.9451,  0.9854, -0.8497,  0.9811,\n",
      "         -0.9693,  0.9996,  0.9995,  0.9899, -0.9825, -0.9966, -0.9860, -0.9968,\n",
      "         -0.7833,  0.9476,  0.9998,  0.9233,  0.9271, -0.8613, -0.9673,  1.0000,\n",
      "         -0.9454, -0.9875, -0.8541, -0.8751, -0.9969,  0.9989,  0.7270,  0.9842,\n",
      "         -0.9445, -0.9717, -0.9909,  0.9908,  0.8037,  0.9995, -0.9668, -0.9982,\n",
      "         -0.9823, -0.9886,  0.7518, -0.8502, -0.9879,  0.6244, -0.9827,  0.9293,\n",
      "          0.8971,  0.9362, -0.9998,  1.0000,  1.0000,  0.9911,  0.9562,  0.9861,\n",
      "         -1.0000, -0.9016,  1.0000, -1.0000, -1.0000, -0.9825, -0.9820,  0.7614,\n",
      "         -1.0000, -0.7959, -0.7714, -0.9607,  0.9975,  0.9908,  1.0000, -1.0000,\n",
      "          0.9327,  0.9805, -0.9154,  0.9999, -0.9488,  0.9917,  0.9475,  0.9003,\n",
      "         -0.8202,  0.9048, -0.9998, -0.9931, -0.9955, -0.9966,  1.0000,  0.7992,\n",
      "         -0.9621, -0.9790,  0.9645, -0.7639,  0.7557, -0.9846, -0.8297,  0.9928,\n",
      "          0.9768,  0.8190,  0.7817, -0.8871,  0.8774,  0.9250,  0.8532,  0.8793,\n",
      "         -0.9656, -0.8422, -0.7269,  0.8421, -0.9938, -0.9851,  0.9891, -0.8646,\n",
      "          0.9995,  1.0000,  0.9560, -0.9844,  0.9578,  0.8733, -0.8081,  1.0000,\n",
      "          0.9750, -0.9936, -0.8880,  0.9814, -0.9667, -0.9790,  1.0000, -0.8456,\n",
      "         -0.9983, -0.9901,  0.9941, -0.9965,  1.0000, -0.9570, -0.9860,  0.9778,\n",
      "          0.9768, -0.9830, -0.7679,  0.8500, -0.9934,  0.8803, -0.9935,  0.9773,\n",
      "          0.9647, -0.7705,  0.9684, -0.9891, -0.8739,  0.8151, -0.9934, -0.8723,\n",
      "          0.9997,  0.9300, -0.8082,  0.6583, -0.8979, -0.8516, -0.9808,  0.9126,\n",
      "          1.0000, -0.9215,  0.9975, -0.9418, -0.6139,  0.8479,  0.9366,  0.9609,\n",
      "         -0.8403, -0.9529,  0.9962, -0.9994, -0.9959,  0.9564,  0.8135, -0.7838,\n",
      "          1.0000,  0.9570,  0.8088,  0.9382,  1.0000,  0.6965,  0.8618,  0.9999,\n",
      "          0.9941, -0.8132,  0.8902,  0.9839, -0.9999, -0.8298, -0.9168,  0.5904,\n",
      "         -0.9628, -0.6558, -0.9873,  0.9904,  0.9999,  0.9146,  0.8670,  0.9921,\n",
      "          1.0000, -0.8895,  0.9396, -0.9640,  0.9935, -1.0000, -0.9841, -0.8653,\n",
      "         -0.8152, -0.9992, -0.8505,  0.8440, -0.9885,  0.9992,  0.9912, -0.9999,\n",
      "         -0.9970, -0.9531,  0.9914,  0.7773, -1.0000, -0.9837, -0.7671,  0.9900,\n",
      "         -0.8910, -0.9886, -0.9725, -0.9325,  0.9094, -0.8535,  0.8608,  0.9995,\n",
      "         -0.6547, -0.9958, -0.8629, -0.7218, -0.9791,  0.9889, -0.9837, -0.9999,\n",
      "         -0.7662,  1.0000, -0.9023,  0.9993,  0.9511,  0.9851, -0.8393,  0.7323,\n",
      "          0.9997,  0.8835, -0.9986, -0.9999, -0.9914, -0.9225,  0.9415,  0.9898,\n",
      "          0.9934,  0.9503,  0.9852,  0.8255, -0.7607,  0.8167,  1.0000, -0.8010,\n",
      "         -0.8082, -0.9338, -0.8384, -0.8768, -0.9231,  1.0000,  0.7880,  0.9713,\n",
      "         -0.9968, -0.9992, -0.9954,  1.0000,  0.9582, -0.8724,  0.9688,  0.9395,\n",
      "         -0.7936,  0.9915, -0.8473, -0.7974,  0.8636,  0.7830,  0.9897, -0.9647,\n",
      "         -0.9906, -0.9045,  0.9309, -0.9883,  1.0000, -0.9618, -0.8489, -0.8279,\n",
      "         -0.9613,  0.9557,  0.5925, -0.9922, -0.8468,  0.8826,  0.9914,  0.8413,\n",
      "         -0.9080, -0.9873,  0.9994,  0.9980, -0.9998, -0.9594,  0.9890, -0.9911,\n",
      "          0.9434,  1.0000,  0.8804,  0.9685,  0.8710, -0.9237,  0.9206, -0.9479,\n",
      "          0.9743, -0.9864, -0.8990, -0.8415,  0.8650, -0.8731, -0.9073,  0.8680,\n",
      "          0.7664, -0.8537, -0.9525, -0.8496,  0.9093,  0.9942, -0.8166, -0.8006,\n",
      "          0.7757, -0.8033, -0.9939, -0.8951, -0.9332, -1.0000,  0.9522, -1.0000,\n",
      "          0.9868,  0.9407, -0.8198,  0.9641,  0.8506,  0.9836, -0.9498, -0.9997,\n",
      "         -0.9287,  0.9300, -0.9268, -0.9709, -0.8925,  0.9216, -0.7871,  0.7643,\n",
      "         -0.9861,  0.9145, -0.8821,  1.0000,  0.8287, -0.9831, -0.9995,  0.7575,\n",
      "         -0.8744,  1.0000, -0.9962, -0.9914,  0.8690, -0.9908, -0.9435,  0.9056,\n",
      "          0.7206, -0.9753, -0.9999,  0.9900,  0.9974, -0.7962,  0.9548, -0.8898,\n",
      "         -0.9275,  0.6768,  0.9993,  0.9947,  0.9584,  0.9943, -0.9274, -0.9002,\n",
      "          0.9892,  0.8842,  0.9477,  0.8104,  1.0000,  0.8807, -0.9727, -0.8047,\n",
      "         -0.9947, -0.8880, -0.9881,  0.8756,  0.8827,  0.9871, -0.8747,  0.9960,\n",
      "         -0.9995,  0.7311, -0.9894, -0.9946,  0.8940, -0.9790, -0.9940, -0.9943,\n",
      "          0.9687, -0.8512, -0.7848,  0.8410,  0.8014,  0.9446,  0.9048, -1.0000,\n",
      "          0.9837,  0.9284,  0.9998,  0.9851,  0.9717,  0.9452,  0.8664, -0.9968,\n",
      "         -0.9997, -0.9050, -0.7906,  0.9742,  0.9655,  0.9748,  0.9284, -0.8430,\n",
      "         -0.8762, -0.9946, -0.9477, -0.9964,  0.9021, -0.9962, -0.9988,  0.9887,\n",
      "          0.8127, -0.7855, -0.9414, -0.9962,  0.9937,  0.9342,  0.8926,  0.6122,\n",
      "          0.8636,  0.9639,  0.9956,  0.9932, -0.9989,  0.9784, -0.9958,  0.9081,\n",
      "          0.7801, -0.9712,  0.8203,  0.9768, -0.9414,  0.8844, -0.8694, -0.9985,\n",
      "          0.9025, -0.8136,  0.9333, -0.8561, -0.7435, -0.8815, -0.7599, -0.9438,\n",
      "         -0.9715,  0.8512,  0.9008,  0.9697,  0.9934, -0.8076, -0.9854, -0.7668,\n",
      "         -0.9970, -0.9721,  0.9962, -0.8269, -0.9562,  0.9910,  0.7108,  0.8851,\n",
      "          0.9159, -0.8698, -0.8930, -0.9773,  0.9595, -0.8953, -0.9546, -0.9663,\n",
      "          0.9327,  0.8168,  1.0000, -0.9988, -0.9998, -0.8792, -0.8959,  0.7752,\n",
      "         -0.9278, -1.0000,  0.8906, -0.9637,  0.9884, -0.9950,  0.9985, -0.9947,\n",
      "         -0.9992, -0.8489,  0.9573,  0.9975, -0.9056, -0.9813,  0.8531, -0.9146,\n",
      "          1.0000,  0.9458, -0.9739, -0.8547,  0.9005, -0.9965, -0.9490,  0.9859]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(headless(**(dataset.remove_columns('labels')[0:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6abe4e7-f220-410f-8af8-a3e87dd9990b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.0348, 0.1623]]), hidden_states=(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
      "         [ 0.5956,  0.5420,  0.0412,  ...,  0.4376,  0.5639,  0.3365],\n",
      "         [-0.5427,  0.3790, -0.4397,  ...,  0.5385,  1.1806, -0.9872],\n",
      "         ...,\n",
      "         [ 0.6080,  0.1944, -0.4991,  ...,  0.1576,  0.0924,  0.0526],\n",
      "         [-0.1864,  0.2774, -0.2251,  ...,  0.7510,  0.4162,  0.3754],\n",
      "         [-0.4083, -0.0742, -0.2198,  ..., -0.0169,  0.0754, -0.1792]]]), tensor([[[ 0.0145,  0.0151, -0.2307,  ...,  0.2228, -0.1197, -0.0114],\n",
      "         [ 0.7825,  0.7195,  0.0461,  ...,  0.5636,  0.5113,  0.3183],\n",
      "         [-0.5592,  0.4928, -0.4244,  ..., -0.2110,  0.5988, -0.9690],\n",
      "         ...,\n",
      "         [ 0.8251,  0.8316, -0.2125,  ...,  0.2319, -0.2733, -0.4672],\n",
      "         [-0.1086,  0.1292, -0.1864,  ...,  0.3960,  0.1578,  0.1404],\n",
      "         [-0.1343,  0.0762, -0.0862,  ...,  0.1826,  0.3630, -0.0585]]]), tensor([[[-0.1319, -0.2054, -0.4479,  ...,  0.2042,  0.0758, -0.0101],\n",
      "         [ 0.5535,  0.9610,  0.3722,  ...,  0.4701,  0.3691,  0.4044],\n",
      "         [-0.8092,  0.6785, -0.0977,  ..., -0.4168,  1.2423, -1.2358],\n",
      "         ...,\n",
      "         [ 0.8226,  0.8661,  0.8426,  ...,  0.4655, -0.2906, -0.8651],\n",
      "         [-0.0943, -0.0416,  0.2452,  ...,  0.1061,  0.0119,  0.2596],\n",
      "         [-0.2324,  0.0235, -0.0069,  ...,  0.2451,  0.3566, -0.2651]]]), tensor([[[-0.0744, -0.3727, -0.1825,  ...,  0.1338,  0.2620,  0.0874],\n",
      "         [ 0.2225,  0.5541,  0.6707,  ...,  0.1888,  0.4204,  0.2933],\n",
      "         [-0.9040,  1.1963,  0.5895,  ..., -0.4704,  0.5186, -0.9711],\n",
      "         ...,\n",
      "         [ 1.1334,  0.5586,  0.6567,  ...,  0.2142, -0.4712, -1.4615],\n",
      "         [-0.2634, -0.0522,  0.4869,  ...,  0.0205, -0.0054, -0.1274],\n",
      "         [-0.0586, -0.0627,  0.1144,  ...,  0.1142,  0.0790, -0.0548]]]), tensor([[[ 0.0886, -0.6866, -0.5459,  ...,  0.0701,  0.3646,  0.2542],\n",
      "         [-0.0494,  0.4330,  0.5426,  ...,  0.1228,  0.2673,  0.1039],\n",
      "         [-0.8562,  0.9381,  0.3800,  ..., -0.5916,  0.8701, -0.7979],\n",
      "         ...,\n",
      "         [ 1.0738,  0.3442,  0.1038,  ...,  0.4267, -0.4280, -1.4848],\n",
      "         [-0.3499,  0.2145,  0.3117,  ..., -0.2297, -0.1790, -0.0944],\n",
      "         [-0.0327, -0.0381, -0.0040,  ...,  0.0378,  0.0453, -0.0288]]]), tensor([[[ 0.0173, -0.4982, -0.4726,  ..., -0.3489,  0.2356,  0.0228],\n",
      "         [-0.6924,  0.2140,  0.0388,  ...,  0.1122,  0.5587,  0.3180],\n",
      "         [-1.6207,  0.7624,  0.0312,  ..., -0.8516,  0.6440, -0.3536],\n",
      "         ...,\n",
      "         [ 1.2272,  0.0518,  0.0940,  ...,  0.6483, -0.5969, -1.5111],\n",
      "         [-0.3688,  0.1581,  0.2022,  ..., -0.1236, -0.0182, -0.0209],\n",
      "         [-0.0255, -0.0214,  0.0128,  ...,  0.0271,  0.0039, -0.0267]]]), tensor([[[-0.2600, -0.2263, -0.8883,  ..., -1.0375, -0.1625,  0.1468],\n",
      "         [-1.3701,  0.4518, -0.3379,  ..., -0.8371, -0.3594,  0.4302],\n",
      "         [-1.8937,  0.5620, -0.0198,  ..., -1.1599,  0.0422, -0.8098],\n",
      "         ...,\n",
      "         [ 1.1101,  0.0264,  0.3000,  ...,  0.4922, -0.1990, -1.5646],\n",
      "         [-0.4910,  0.3425, -0.1101,  ..., -0.7629, -0.1478,  0.2030],\n",
      "         [ 0.0100, -0.0115, -0.0153,  ...,  0.0102, -0.0201, -0.0407]]]), tensor([[[-0.2034, -0.1746, -0.8434,  ..., -1.6621, -0.4261,  0.3586],\n",
      "         [-1.2273,  0.3629, -0.7486,  ..., -0.7331, -0.1083,  0.5227],\n",
      "         [-1.8408,  0.4568, -0.6993,  ..., -0.8646,  0.0042, -0.4150],\n",
      "         ...,\n",
      "         [ 0.9420, -0.3283,  0.1197,  ...,  0.3392, -0.0713, -1.2726],\n",
      "         [-0.7366, -0.0333,  0.0877,  ..., -0.8796,  0.2809,  0.2318],\n",
      "         [ 0.0296,  0.0095, -0.0301,  ..., -0.0139, -0.0139, -0.0498]]]), tensor([[[-0.2665, -0.0578, -1.0095,  ..., -1.1971,  0.0866,  0.3704],\n",
      "         [-1.4605,  0.5435, -0.7243,  ...,  0.0366, -0.2335,  0.3351],\n",
      "         [-1.9093,  0.4807, -0.4525,  ..., -0.6076, -0.1121, -0.1763],\n",
      "         ...,\n",
      "         [ 0.6297, -0.7687, -0.0552,  ...,  0.1229, -0.7922, -1.0787],\n",
      "         [-0.3657,  0.0866, -0.4304,  ..., -0.6176,  0.1318,  0.1702],\n",
      "         [ 0.0623,  0.0504,  0.0217,  ..., -0.0306, -0.0610, -0.0357]]]), tensor([[[-0.7281, -0.1600, -1.0031,  ..., -0.7532,  0.2771,  0.3523],\n",
      "         [-1.1470,  0.7775, -0.6943,  ..., -0.3299,  0.1508, -0.0037],\n",
      "         [-1.7227,  0.1788, -0.5804,  ..., -0.6679,  0.0197, -0.5190],\n",
      "         ...,\n",
      "         [ 0.5307, -0.9824,  0.3342,  ...,  0.3326, -1.1303, -1.1620],\n",
      "         [ 0.0352,  0.3086, -0.3152,  ..., -0.3792, -0.1150,  0.1325],\n",
      "         [ 0.0555,  0.0751,  0.0027,  ..., -0.0341, -0.0466,  0.0380]]]), tensor([[[-0.9457, -0.2487, -0.5836,  ..., -0.7077,  0.3052,  0.3346],\n",
      "         [-1.0747,  0.5282, -0.3410,  ..., -0.7371, -0.3423,  0.0854],\n",
      "         [-1.8009,  0.2300, -0.4077,  ..., -1.0399, -0.2398, -0.6830],\n",
      "         ...,\n",
      "         [ 0.6684, -1.2943,  0.6297,  ...,  0.0021, -1.3392, -1.5292],\n",
      "         [ 0.0126,  0.0231, -0.0569,  ...,  0.0083, -0.0243, -0.0020],\n",
      "         [ 0.0130, -0.0056, -0.0305,  ...,  0.0212, -0.0344,  0.0214]]]), tensor([[[-6.9135e-01,  1.2543e-01, -5.9030e-01,  ..., -2.5643e-01,\n",
      "          -6.9979e-02,  3.2042e-01],\n",
      "         [-6.8254e-01,  5.1332e-01, -5.0361e-01,  ..., -5.7758e-01,\n",
      "          -1.7233e-01,  8.4502e-02],\n",
      "         [-1.7933e+00, -5.0047e-02, -6.5987e-01,  ..., -7.6121e-01,\n",
      "          -1.9155e-01, -8.0564e-01],\n",
      "         ...,\n",
      "         [ 5.1524e-01, -1.1234e+00,  5.9130e-01,  ..., -3.7347e-01,\n",
      "          -1.6188e+00, -1.3588e+00],\n",
      "         [ 4.8029e-02,  2.9867e-02, -4.6890e-02,  ..., -2.9728e-04,\n",
      "          -1.0314e-02,  1.1210e-02],\n",
      "         [ 4.6285e-02,  2.4298e-02, -4.7411e-02,  ...,  1.1726e-03,\n",
      "          -1.6103e-02,  1.3326e-02]]]), tensor([[[-0.8701,  0.1044, -0.8448,  ..., -0.7244,  0.2107,  0.1728],\n",
      "         [-0.8112,  0.1907, -0.9818,  ..., -0.3051,  0.4335,  0.0024],\n",
      "         [-1.1000, -0.3378, -0.5038,  ..., -0.3010,  0.1676, -0.4993],\n",
      "         ...,\n",
      "         [ 0.2257, -0.6626,  0.3625,  ..., -0.3866, -0.8420, -0.8623],\n",
      "         [ 0.6308,  0.0563, -0.5607,  ..., -0.0981, -0.4543, -0.2846],\n",
      "         [ 0.6324,  0.0537, -0.5595,  ..., -0.0900, -0.4814, -0.2747]]])), attentions=None)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(classifier(**(dataset.remove_columns('labels')[0:1]),output_hidden_states=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "609affa8-dae2-4917-a2f9-6e7d976f6798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1037,  2711,  2006,  1037,  3586, 14523,  2058,  1037,  3714,\n",
       "          2091, 13297,  1012,   102,  1037,  2711,  2003,  2731,  2010,  3586,\n",
       "          2005,  1037,  2971,  1012,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10faab76-c061-41cb-b899-a5be0c4fb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representation(examples):\n",
    "    # print(examples)\n",
    "    with torch.no_grad():\n",
    "        return {'z': headless(**tokenizer(examples['premise'],examples['hypothesis'],return_tensors='pt',truncation=True,padding=True)).pooler_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d62eef3f-befc-407e-9a9f-0144a05e07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(get_representation,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a6386d7-ddbc-4508-933b-be54ab548f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,   7,  14,  17,  18,  23,  25,  29,  31,  35,  37,  40,\n",
       "        43,  44,  45,  49,  52,  56,  59,  60,  63,  67,  70,  74,  77,\n",
       "        79,  83,  84,  88,  91,  96,  99, 103, 104, 106, 109, 112, 116,\n",
       "       117, 122, 125, 127, 131, 133, 135, 138, 142, 144, 148, 150, 154,\n",
       "       157, 158, 162, 165, 168, 171, 172, 173, 175, 183, 186, 187, 190,\n",
       "       194, 198, 202, 205, 208, 210, 214, 216, 218, 222, 223, 227, 231,\n",
       "       232, 237, 241, 242, 246, 248, 250, 257, 261, 262, 265, 267, 270,\n",
       "       272, 277, 279, 282, 284, 288, 293, 294, 299, 300, 302, 305, 306,\n",
       "       308, 312, 318, 322, 323, 329, 333, 334, 335, 338, 343, 346, 349,\n",
       "       351, 355, 357, 360, 363, 367, 368, 371, 374, 378, 381, 385, 388,\n",
       "       391, 393, 397, 400, 401, 405, 408, 411, 414, 417, 420, 422, 425,\n",
       "       428, 432, 434, 437, 442, 443, 448, 450, 451, 454, 455, 458, 461,\n",
       "       465, 469, 473, 477, 480, 483, 486, 490, 493, 495, 499, 500, 504,\n",
       "       506, 510, 512, 516, 519, 520, 522, 525, 531, 535, 537, 540, 543,\n",
       "       546, 550, 553, 555, 557, 561, 563, 566, 571, 573, 575, 580, 583,\n",
       "       586, 587, 590, 595, 598, 601, 603, 606, 610, 613, 616, 617, 622,\n",
       "       624, 628, 631, 633, 635, 640, 642, 644, 648, 652, 653, 656, 659,\n",
       "       664, 665, 670, 671, 674, 677, 680, 683, 688, 691, 694, 697, 700,\n",
       "       701, 704, 706, 708, 711, 713, 718, 720, 723, 731, 735, 736, 738,\n",
       "       739, 742, 744, 746, 750, 753, 756, 760, 762, 764, 769, 770, 774,\n",
       "       776, 781, 786, 787, 792, 794, 797, 801, 804, 806, 809, 813, 816,\n",
       "       817, 820, 824, 828, 832, 833, 834, 836, 843, 844, 848, 850, 853,\n",
       "       856, 861, 862, 865, 870, 873, 876, 877, 882, 883, 887, 889, 893,\n",
       "       896, 900, 901, 904, 907, 911, 915, 916, 919, 922, 926, 929, 933,\n",
       "       936, 937, 941, 945, 947, 951, 953, 957, 960, 961, 966, 967, 968,\n",
       "       971, 974, 982, 983, 988, 991, 993, 996, 997])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dataset['labels']==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ddc6a2a-8a76-43f4-bc20-d02a9f6bf0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9884, -0.9076, -0.9998,  ..., -0.9965, -0.9490,  0.9859],\n",
       "        [-0.9822, -0.8889, -0.9999,  ..., -0.9971, -0.9156,  0.9796],\n",
       "        [-0.9899, -0.9047, -0.9997,  ..., -0.9913, -0.9477,  0.9897],\n",
       "        ...,\n",
       "        [-0.9829, -0.8738, -0.9998,  ..., -0.9962, -0.9162,  0.9777],\n",
       "        [-0.9935, -0.9265, -0.9999,  ..., -0.9970, -0.9585,  0.9931],\n",
       "        [-0.9811, -0.8282, -0.9977,  ..., -0.9596, -0.9331,  0.9816]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(np.where(dataset['labels']==1)[0])['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26f1d3ca-6553-44ec-93e3-fdc01366b50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9724, -0.8671, -0.9867,  0.9667,  0.9691, -0.7423,  0.9770,  0.7845,\n",
       "        -0.9811, -0.9882, -0.9270,  0.9860,  0.9881,  0.9449,  0.9792, -0.9513,\n",
       "        -0.9219, -0.8780,  0.7194, -0.8989,  0.9415,  0.9880, -0.8232,  0.7591,\n",
       "         0.8617,  0.9870, -0.9500,  0.9676,  0.9758,  0.8635, -0.9409,  0.7241,\n",
       "        -0.9941, -0.7040, -0.9868, -0.9904,  0.8789, -0.8784, -0.6542, -0.5599,\n",
       "        -0.9595,  0.7716,  0.9880,  0.6509,  0.8973, -0.7636, -0.9880,  0.7787,\n",
       "        -0.9456,  0.9857,  0.9840,  0.9829,  0.7463,  0.8924,  0.8858, -0.8915,\n",
       "         0.5963,  0.6994, -0.7453, -0.9108, -0.8574,  0.8161, -0.9843, -0.9525,\n",
       "         0.9845,  0.9814, -0.7861, -0.7937, -0.7410,  0.5514,  0.9772,  0.7374,\n",
       "        -0.7262, -0.9265,  0.9782,  0.8218, -0.8628,  0.9880, -0.9105, -0.9882,\n",
       "         0.9842,  0.9817,  0.8601, -0.9563,  0.9445, -0.9880,  0.9293, -0.6590,\n",
       "        -0.9927,  0.7371,  0.9310, -0.7772,  0.9698,  0.8797, -0.9228, -0.9150,\n",
       "        -0.8631, -0.9820, -0.7904, -0.8879,  0.6693, -0.7844, -0.8896, -0.7990,\n",
       "         0.8058, -0.9065, -0.8978,  0.8246,  0.8828,  0.9221,  0.7788, -0.8162,\n",
       "         0.8864, -0.9779,  0.9260, -0.7897, -0.9933, -0.8607, -0.9930,  0.8922,\n",
       "        -0.8842, -0.7891,  0.9840, -0.8977,  0.8231, -0.7551, -0.9858, -0.9880,\n",
       "        -0.9470, -0.9266, -0.8241, -0.8417, -0.9853, -0.9749,  0.9366,  0.9713,\n",
       "         0.7649,  0.9880, -0.8584,  0.9732, -0.9099, -0.9587,  0.9695, -0.8815,\n",
       "         0.9597,  0.8443, -0.9409,  0.7598, -0.8536,  0.9258, -0.9698, -0.7970,\n",
       "        -0.9803, -0.9604, -0.7456,  0.9774, -0.9685, -0.9864, -0.8780, -0.7773,\n",
       "        -0.9056,  0.9460,  0.9463,  0.8480, -0.8767,  0.8679,  0.9179,  0.8886,\n",
       "        -0.9496, -0.8230,  0.8529, -0.8247, -0.9844, -0.9889, -0.8609,  0.7718,\n",
       "         0.9936,  0.9218,  0.8033,  0.9780, -0.7714,  0.9621, -0.9812,  0.9908,\n",
       "        -0.7444,  0.6895, -0.9376,  0.8908, -0.9576,  0.7818,  0.9693, -0.9617,\n",
       "        -0.8834, -0.7655, -0.7675, -0.8425, -0.9796,  0.8657, -0.7820, -0.7076,\n",
       "        -0.6873,  0.9538,  0.9863,  0.9222,  0.9422,  0.9036, -0.9666, -0.8607,\n",
       "         0.7255,  0.7111,  0.7564,  0.9958, -0.9519, -0.7492, -0.9649, -0.9903,\n",
       "         0.5877, -0.9575, -0.7407, -0.9090,  0.9616, -0.9319,  0.9556,  0.8326,\n",
       "        -0.9866, -0.9252,  0.8269, -0.8595,  0.8867, -0.7310,  0.8840,  0.9867,\n",
       "        -0.9156,  0.9458,  0.9599, -0.9860, -0.9196,  0.9652, -0.7936,  0.9619,\n",
       "        -0.9440,  0.9885,  0.9848,  0.9616, -0.9680, -0.9801, -0.9603, -0.9786,\n",
       "        -0.7331,  0.8925,  0.9858,  0.8918,  0.8657, -0.7491, -0.9422,  0.9879,\n",
       "        -0.9071, -0.9769, -0.8457, -0.8262, -0.9924,  0.9848,  0.6698,  0.9491,\n",
       "        -0.9046, -0.9498, -0.9864,  0.9753,  0.7262,  0.9872, -0.9112, -0.9831,\n",
       "        -0.9626, -0.9745,  0.6472, -0.7864, -0.9600,  0.4856, -0.9757,  0.8802,\n",
       "         0.8473,  0.8939, -0.9861,  0.9879,  0.9880,  0.9833,  0.9355,  0.9705,\n",
       "        -0.9880, -0.8918,  0.9882, -0.9876, -0.9880, -0.9730, -0.9610,  0.7524,\n",
       "        -0.9880, -0.7121, -0.6740, -0.9566,  0.9784,  0.9868,  0.9877, -0.9880,\n",
       "         0.9189,  0.9705, -0.8945,  0.9858, -0.9055,  0.9841,  0.9204,  0.8466,\n",
       "        -0.7490,  0.8462, -0.9867, -0.9752, -0.9735, -0.9775,  0.9879,  0.7425,\n",
       "        -0.9365, -0.9678,  0.9213, -0.7290,  0.7515, -0.9796, -0.7988,  0.9693,\n",
       "         0.9602,  0.7296,  0.7705, -0.8457,  0.8043,  0.8414,  0.7560,  0.8630,\n",
       "        -0.9562, -0.8304, -0.7362,  0.7458, -0.9727, -0.9777,  0.9813, -0.8437,\n",
       "         0.9848,  0.9880,  0.9341, -0.9680,  0.9351,  0.8546, -0.8175,  0.9880,\n",
       "         0.9579, -0.9861, -0.8645,  0.9563, -0.9410, -0.9516,  0.9898, -0.7770,\n",
       "        -0.9775, -0.9629,  0.9860, -0.9927,  0.9879, -0.9496, -0.9807,  0.9826,\n",
       "         0.9657, -0.9517, -0.7884,  0.7969, -0.9730,  0.8372, -0.9812,  0.9581,\n",
       "         0.9098, -0.6837,  0.9514, -0.9667, -0.8307,  0.7362, -0.9602, -0.8529,\n",
       "         0.9868,  0.9043, -0.7464,  0.5947, -0.8201, -0.8265, -0.9779,  0.8877,\n",
       "         0.9880, -0.8775,  0.9812, -0.9274, -0.5532,  0.7705,  0.9015,  0.9302,\n",
       "        -0.8266, -0.9284,  0.9781, -0.9863, -0.9910,  0.9330,  0.7499, -0.7067,\n",
       "         0.9880,  0.9227,  0.7681,  0.9011,  0.9873,  0.5993,  0.8145,  0.9854,\n",
       "         0.9893, -0.7448,  0.8674,  0.9624, -0.9859, -0.7629, -0.8901,  0.5805,\n",
       "        -0.9492, -0.5684, -0.9862,  0.9841,  0.9863,  0.8698,  0.8005,  0.9650,\n",
       "         0.9880, -0.8698,  0.9071, -0.8804,  0.9722, -0.9879, -0.9676, -0.8321,\n",
       "        -0.7228, -0.9838, -0.8248,  0.7836, -0.9843,  0.9822,  0.9673, -0.9874,\n",
       "        -0.9944, -0.9050,  0.9686,  0.6931, -0.9878, -0.9622, -0.7566,  0.9717,\n",
       "        -0.8187, -0.9832, -0.9237, -0.8386,  0.8731, -0.7624,  0.8206,  0.9840,\n",
       "        -0.4833, -0.9778, -0.8525, -0.6247, -0.9588,  0.9610, -0.9559, -0.9863,\n",
       "        -0.7017,  0.9880, -0.8805,  0.9852,  0.9353,  0.9526, -0.7480,  0.6758,\n",
       "         0.9869,  0.8255, -0.9805, -0.9851, -0.9409, -0.8895,  0.8884,  0.9670,\n",
       "         0.9753,  0.9230,  0.9644,  0.7606, -0.6918,  0.7372,  0.9879, -0.7399,\n",
       "        -0.7464, -0.8871, -0.7355, -0.8285, -0.8042,  0.9880,  0.7578,  0.9454,\n",
       "        -0.9943, -0.9849, -0.9780,  0.9880,  0.9385, -0.8331,  0.9422,  0.9232,\n",
       "        -0.7137,  0.9703, -0.7932, -0.7334,  0.8047,  0.7156,  0.9809, -0.9303,\n",
       "        -0.9866, -0.8269,  0.8966, -0.9820,  0.9880, -0.9265, -0.7999, -0.8171,\n",
       "        -0.9363,  0.8796,  0.5514, -0.9896, -0.7891,  0.7962,  0.9852,  0.7546,\n",
       "        -0.8704, -0.9730,  0.9825,  0.9798, -0.9856, -0.9541,  0.9830, -0.9875,\n",
       "         0.9274,  0.9880,  0.7923,  0.9258,  0.8075, -0.8561,  0.8817, -0.9094,\n",
       "         0.9468, -0.9788, -0.8334, -0.7658,  0.8163, -0.7638, -0.8811,  0.8666,\n",
       "         0.6705, -0.8316, -0.9217, -0.7672,  0.8785,  0.9760, -0.7502, -0.7447,\n",
       "         0.6939, -0.7195, -0.9813, -0.8705, -0.8857, -0.9880,  0.9012, -0.9880,\n",
       "         0.9613,  0.9035, -0.7193,  0.9490,  0.8318,  0.9619, -0.9272, -0.9840,\n",
       "        -0.8277,  0.9206, -0.8755, -0.9453, -0.8897,  0.8759, -0.6995,  0.7306,\n",
       "        -0.9535,  0.8809, -0.7921,  0.9880,  0.7307, -0.9486, -0.9869,  0.7143,\n",
       "        -0.8111,  0.9880, -0.9779, -0.9807,  0.8376, -0.9580, -0.9339,  0.8495,\n",
       "         0.6388, -0.9515, -0.9870,  0.9782,  0.9755, -0.7927,  0.9199, -0.8180,\n",
       "        -0.8698,  0.6192,  0.9842,  0.9917,  0.9283,  0.9822, -0.8783, -0.8662,\n",
       "         0.9807,  0.7928,  0.8952,  0.7143,  0.9880,  0.8191, -0.9612, -0.7696,\n",
       "        -0.9877, -0.8209, -0.9773,  0.8217,  0.8434,  0.9781, -0.7929,  0.9867,\n",
       "        -0.9851,  0.6469, -0.9567, -0.9668,  0.8371, -0.9711, -0.9881, -0.9889,\n",
       "         0.9443, -0.7848, -0.6636,  0.7419,  0.6340,  0.9062,  0.8646, -0.9880,\n",
       "         0.9728,  0.8563,  0.9859,  0.9829,  0.9599,  0.9144,  0.7777, -0.9919,\n",
       "        -0.9870, -0.8606, -0.7516,  0.9470,  0.9387,  0.9555,  0.8847, -0.8022,\n",
       "        -0.8371, -0.9680, -0.9126, -0.9939,  0.8511, -0.9713, -0.9848,  0.9797,\n",
       "         0.7375, -0.6774, -0.8897, -0.9798,  0.9747,  0.9241,  0.8309,  0.5962,\n",
       "         0.8112,  0.9551,  0.9818,  0.9864, -0.9851,  0.9351, -0.9748,  0.8804,\n",
       "         0.7618, -0.9558,  0.7436,  0.9399, -0.9009,  0.7909, -0.8012, -0.9855,\n",
       "         0.8520, -0.7589,  0.9139, -0.8451, -0.6625, -0.8178, -0.7117, -0.8972,\n",
       "        -0.9593,  0.8560,  0.8532,  0.9512,  0.9775, -0.6943, -0.9619, -0.7233,\n",
       "        -0.9788, -0.9581,  0.9808, -0.7567, -0.9184,  0.9664,  0.6257,  0.9061,\n",
       "         0.8924, -0.8285, -0.8541, -0.9490,  0.9414, -0.8521, -0.9252, -0.9412,\n",
       "         0.9266,  0.7783,  0.9880, -0.9821, -0.9856, -0.8119, -0.8568,  0.7652,\n",
       "        -0.9021, -0.9880,  0.8364, -0.9406,  0.9726, -0.9736,  0.9840, -0.9726,\n",
       "        -0.9868, -0.8102,  0.9081,  0.9753, -0.8658, -0.9510,  0.8304, -0.8818,\n",
       "         0.9872,  0.9327, -0.8656, -0.7418,  0.8872, -0.9722, -0.9231,  0.9788])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(dataset.select(np.where(dataset['labels']==1)[0])['z'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd6c54f5-ff56-4549-99d5-036efdc93675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_center(dataset):\n",
    "    centers = {}\n",
    "    for c in np.unique(dataset['labels']):\n",
    "        centers[c] = torch.mean(dataset.select(np.where(dataset['labels']==c)[0])['z'],axis=0)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4df6ebb-5717-48cc-8a4f-1bd75dc7bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = calculate_class_center(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cdf4c723-4092-4299-a408-4401f6ae8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.stack([centers[c.item()] for c in dataset[0:10]['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "068058c2-0f83-4375-92d7-521fc718e7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9724, -0.8671, -0.9867,  ..., -0.9722, -0.9231,  0.9788],\n",
       "        [-0.9448, -0.8105, -0.9530,  ..., -0.9239, -0.8883,  0.9686],\n",
       "        [-0.9772, -0.8664, -0.9912,  ..., -0.9740, -0.9257,  0.9812],\n",
       "        ...,\n",
       "        [-0.9772, -0.8664, -0.9912,  ..., -0.9740, -0.9257,  0.9812],\n",
       "        [-0.9724, -0.8671, -0.9867,  ..., -0.9722, -0.9231,  0.9788],\n",
       "        [-0.9724, -0.8671, -0.9867,  ..., -0.9722, -0.9231,  0.9788]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "750ba73e-4e09-440b-8e75-0401144bbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(examples):\n",
    "    cc = torch.stack([centers[c.item()] for c in examples['labels']])\n",
    "    return {'dist': torch.linalg.norm(examples['z'] - cc,dim=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "685c3c08-ad90-43ab-8b1d-204200b4f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████| 998/998 [00:00<00:00, 1517.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(get_dist,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0bae4880-49d3-4fbe-b1ef-534e516ec875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6096)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['dist'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2806cd93-849c-488d-9696-a33ce6cf5541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([861,  56, 933, 312, 936, 993, 307,  93, 929,  12, 171, 576, 210, 503,\n",
       "        962, 537, 853, 388, 530,  53, 354, 701,  71, 265, 357, 250, 306, 367,\n",
       "        968, 209, 198, 378, 191, 116, 291, 631, 458, 872, 305, 945, 104, 302,\n",
       "        970,  40, 661, 162,  89, 418, 680, 289, 922, 826,  29, 924, 316, 205,\n",
       "        350, 677, 967, 543, 419, 230, 117, 828, 214, 166, 238, 601, 451, 359,\n",
       "        674, 261, 889, 926, 798, 202, 642, 975, 930, 859, 897, 624, 915, 645,\n",
       "         63,  84, 170, 262, 896, 594, 882, 901, 297, 989, 118, 536, 183, 583,\n",
       "        766, 393, 442, 847, 587, 365, 374, 258, 430, 479, 712, 637, 126, 473,\n",
       "        165, 149, 839, 285, 996, 820, 288, 448,  45, 484, 932,  60, 525, 893,\n",
       "        110, 633, 389,  30, 831, 401, 356, 635, 483, 443, 698, 586, 469,  57,\n",
       "        618, 688, 628, 876, 703, 921, 445, 925, 848, 978,  52, 540, 142,  88,\n",
       "        606, 883, 641, 404, 127, 776, 775, 822,   8,  34, 362, 405, 420, 836,\n",
       "        369, 434, 480, 403, 160, 600, 386,  35,  44, 630,  15, 172, 622, 854,\n",
       "        375, 759, 433, 613,  79, 216, 634, 890, 913, 823, 957, 682, 221,  20,\n",
       "        190, 311, 779, 803, 493, 453, 351,  59, 589, 269, 870, 379, 522, 811,\n",
       "        995, 372, 900,  13, 818, 220, 498,  81,  67, 884, 192,  77,  23, 108,\n",
       "        187,  42, 494,  18, 665, 982, 428, 381, 130, 115, 413, 432, 462,  21,\n",
       "        892, 656, 140, 295,   2, 598, 585, 815,   7, 657, 157, 817,  39, 257,\n",
       "        973, 788, 808, 679, 667, 784, 264, 475, 549, 751, 855, 778, 834, 201,\n",
       "         95, 862, 643, 816, 499, 829, 226, 863, 426, 764, 150, 395, 416, 868,\n",
       "        450, 768, 248, 286, 384, 695, 423, 488, 683, 838, 805, 542, 308, 538,\n",
       "         61, 790,  83,   0, 161, 914, 875, 770, 249, 737, 294, 864, 738, 254,\n",
       "        145, 422, 320, 189, 610, 141, 719, 743, 809,  11, 119, 539, 242, 345,\n",
       "        984, 301, 188, 245, 740, 233, 833,  76, 992, 991, 227, 255,  54, 707,\n",
       "        987, 672,  36, 754, 928, 937,   5, 640, 337, 518,  78, 505, 234, 949,\n",
       "        346, 534, 713, 533, 155, 997, 197,  41, 279, 417, 972, 424, 911, 436,\n",
       "        974, 806, 124, 590, 881, 125,  31, 314, 298, 531, 860, 300, 748, 612,\n",
       "        919, 341, 774, 760, 799, 129, 217,  51,   3, 449, 807, 136, 371, 801,\n",
       "        231, 904, 626, 668, 109, 951, 927, 843, 203, 459, 709, 898, 742, 662,\n",
       "        802, 603, 559, 228, 886, 988, 215, 690,  85,  68, 902, 319, 572, 486,\n",
       "        437, 953, 577, 912, 544, 705, 741, 370, 223, 781, 653,  46, 208,  80,\n",
       "        237, 966, 946, 455, 406, 535, 137, 944, 106, 604, 943, 392, 758, 123,\n",
       "        761, 644, 520,  43, 103, 394, 611, 398, 994, 824, 980, 842, 218, 560,\n",
       "        138, 460, 317, 958, 517, 903, 336, 969, 151, 616, 184, 471, 558, 414,\n",
       "        954, 782, 135, 154, 571, 521, 409, 178,   9, 200, 573, 429, 128, 322,\n",
       "         87, 352, 193, 660,  37, 940, 732, 427, 472,  96, 524, 482, 343, 519,\n",
       "        819, 550, 100, 909, 678, 777, 961, 222, 866, 513, 144, 557, 131, 659,\n",
       "        887, 702, 253, 553, 614, 241,  64,  17, 686, 438, 282, 792, 596, 917,\n",
       "        468, 335, 204, 681, 964, 179,  14, 654, 767, 812, 821, 358, 710, 721,\n",
       "        309, 425, 457, 731,  98, 173, 697, 402, 315, 935, 568, 638, 407, 175,\n",
       "        446, 206,  55, 552, 435, 918, 360, 232, 101, 684, 797, 467, 865, 168,\n",
       "        120, 725, 873, 931, 196, 340, 290, 888, 548, 252, 556, 272, 753, 780,\n",
       "        664, 752, 509, 105, 304, 696, 474, 756,  91,  92, 693, 605, 283, 397,\n",
       "        595, 361, 787, 111, 769,  99, 906,  38, 280, 299, 199, 757, 303, 454,\n",
       "        608, 880, 720, 916, 647, 268, 950, 169, 714, 744, 325, 965, 602, 952,\n",
       "        153, 323, 791, 673, 646, 871, 749, 229, 691, 658, 156, 908, 132, 676,\n",
       "        163, 271, 947,  32, 990, 332, 867, 490, 387, 649, 148, 441, 979, 599,\n",
       "        794, 704, 708, 837, 411, 102, 212, 339, 275, 905, 333, 563, 292, 963,\n",
       "        844, 495, 461, 219, 651, 565, 456, 687, 845, 570, 591, 620, 655, 240,\n",
       "        619, 814, 277, 976, 894, 260, 338, 746, 470, 729,  62, 334, 412, 485,\n",
       "        715, 869, 597,  33, 617, 147, 421, 879, 636, 181, 796, 938, 648, 699,\n",
       "        578, 364, 685, 112, 891, 899, 516, 728, 274, 762, 246, 632, 363, 581,\n",
       "        447, 621, 293, 511, 795, 986, 960, 259, 670, 270, 694, 584, 329, 878,\n",
       "        910, 580, 366, 400, 491, 497, 941, 718, 331, 353, 625, 287, 877,  70,\n",
       "        344, 545,  19, 588, 415,  10, 349,  86, 207, 122, 835, 439, 955, 267,\n",
       "        390, 380, 523, 532, 706, 785, 730,   4, 182, 477,  16, 139, 133, 629,\n",
       "        735, 810, 382, 324, 747,  74, 476, 143, 716, 496, 765, 247, 546, 376,\n",
       "        121, 783, 348, 263, 773, 504, 669, 410, 804, 895, 830, 225, 939, 582,\n",
       "        174,   1,   6, 256, 923, 134, 492,  94, 874, 663, 159, 330, 529, 569,\n",
       "        554, 856, 276, 607, 959, 114, 971, 251, 771, 593, 981, 266, 615, 736,\n",
       "        510, 444, 328, 983, 763, 239, 512, 528, 211, 164, 296, 244, 849, 243,\n",
       "        281, 675, 236, 948, 526, 176, 373, 489, 562, 692, 841, 146, 399, 551,\n",
       "        750, 158, 167, 977, 755, 942, 273, 574, 639,  22, 846, 508, 107, 745,\n",
       "        213,  47, 527, 564, 623, 907, 717, 310, 180, 278, 727, 858, 514,  97,\n",
       "        177, 934, 327, 627, 152, 793, 772, 185, 813, 723, 194, 734, 235, 541,\n",
       "        700, 689, 592, 985, 722, 347, 711, 463,  25, 956, 609,  73, 724,  90,\n",
       "        666,  66, 326, 547, 579, 452, 857,  48, 789,  69,  75, 733, 284, 478,\n",
       "        487, 561, 786, 832, 652, 465, 396,  27, 383, 440, 575,  72, 355, 391,\n",
       "        368, 885, 650, 464,  50, 431, 825, 318, 515, 739,  49,  26, 313, 920,\n",
       "        506, 385, 186, 377, 567, 671, 827, 726, 195, 408, 852, 555, 224, 321,\n",
       "         24,  82, 800, 566, 342, 113,  58, 850, 840, 481,  28, 851, 500, 466,\n",
       "         65, 507, 501, 502])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(dataset['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c90afab4-0300-481b-a9cf-467ced302179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_select(dataset,fraction):\n",
    "    N = len(dataset)\n",
    "    indices = torch.argsort(dataset['dist'])\n",
    "    start = int(N*(1-fraction)/2)\n",
    "    end = int(N - N*(1-fraction)/2)+1\n",
    "    return indices[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6fcc828f-e68e-44c1-9aff-f772ef16f059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_select(dataset,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0099c-0816-4b7d-bf2d-51cd189ecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def moderate(dataset,fraction):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset = dataset.map(get_representation,batched=True)\n",
    "    centers = calculate_class_center(dataset)\n",
    "    dataset = dataset.map(get_dist,batched=True)\n",
    "    return final_select(dataset,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
